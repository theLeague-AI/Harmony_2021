{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Load the Races dataset\n",
    "df_f1_races = pd.read_csv('races.csv')\n",
    "\n",
    "df_f1_races.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Races dataset\n",
    "df_f1_results= pd.read_csv('f1_results.csv')\n",
    "\n",
    "df_f1_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('the shape of the df_f1_races is', df_f1_races.shape)\n",
    "print('the shape of the df_f1_results is', df_f1_results.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a good understanding of our datasets, we will use the merge function to combine them both into one single dataset for better manipulation of both datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the merge function to gather Results dataset and do a left join on the Races dataset\n",
    "combineddata = df_f1_results.merge(df_f1_races, how = 'left', on='raceId')\n",
    "combineddata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add section on renaming time_x and time_y \n",
    "combineddata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use .info() function to find characteristics of each column in the combined dataset\n",
    "combineddata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Properties: dataframe.describe()\n",
    "\n",
    "Exploratory Data Analysis:\n",
    "\n",
    "- EDA is an approach to analyzing data sets to summarize their main characteristics, often with visual methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combineddata.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise 1***\n",
    "   - Import the titanic data set and find the datas shape, non-null values and data type for each column  and the overall statistical properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the various features present for each passenger on the ship:\n",
    "- **Survived**: Outcome of survival (0 = No; 1 = Yes)...Categorical\n",
    "- **Pclass**: Socio-economic class (1 = Upper class; 2 = Middle class; 3 = Lower class)...categorical\n",
    "- **Name**: Name of passenger...Categorical\n",
    "- **Sex**: Sex of the passenger....Categorical\n",
    "- **Age**: Age of the passenger ....CATEGORICAL\n",
    "- **SibSp**: Number of siblings and spouses of the passenger aboard...Numerical\n",
    "\n",
    "- **Parch**: Number of parents and children of the passenger aboard...?\n",
    "\n",
    "- **Ticket**: Ticket number of the passenger....numerical\n",
    "- **Fare**: Fare paid by the passenger...numerical\n",
    "- **Cabin** Cabin number of the passenger ...categorical\n",
    "- **Embarked**: Port of embarkation of the passenger (C = Cherbourg; Q = Queenstown; S = Southampton)....categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets explore the categorical features of the titanic data set\n",
    "- We can use the value_count() method on each categorical feature to understand what categories the feature is made out of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pp\n",
    "\n",
    "# Import titanic dataset\n",
    "titanic_data = pd.read_csv(\"titanic_data.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the categories under the pclass feature and how many instances of each category are present in our data\n",
    "print(titanic_data.pclass.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that there are 3 categories\n",
    "- All categories are numbers, yet this is still a categorical feature\n",
    "\n",
    "Conclusions:\n",
    "- Most passangers in the titanic were lower class travelers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise 2:***\n",
    "   - Explore the other categorical features of our data set and draw conclusions about our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which column  should you use as your target variable from the given F1 data?\n",
    "- You might say position, but after further evaluation you will realize that the 'position' column has missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the number of empty values in your selected target value\n",
    "combineddata['position'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are 10550 empty records in this column, the data is incomplete and will not allow us to make good predictions of the final position of each racer.\n",
    "\n",
    "Furtunately, we can try another column or gain more data:\n",
    "\n",
    "- Note that there are no empty values in the positionOrder column, this would then be a better target value to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the number of empty values from the 'positionOrder' column\n",
    "combineddata['positionOrder'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***What type of target will we be predicting on?***\n",
    "\n",
    "- If you decide to predict weather a driver will win the race or not, the correct model to use would be a classification model \n",
    "    - The classes for which you will predict are 1 and 0\n",
    "    - 1 = driver wins the race\n",
    "    - 0 = driver does not win the race\n",
    "\n",
    "- Note that the prediction in a classification model can also be called a label.\n",
    "    - In this case we have two labels 1 and 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***In the case of the F1 dataset...***\n",
    "- We must now create a target variable based on the position order column\n",
    "- If the value of 'positionOrder' = 1, the target column will equal 1\n",
    "- If the value of 'positionOrder' != 1, then the target column will equal 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'label' column based on the position order\n",
    "combineddata['label'] = combineddata['positionOrder']==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combineddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the class distribution\n",
    "combineddata.groupby('label')['label'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Note that the negative class has more instances that the positive class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise 3***\n",
    "\n",
    "     1) What type of model do we need to use in order to predict whether or not a passanger survived the titanic based on the given data? (regression/classification) \n",
    "     2) Find the number of positive and negative labels in the titanic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3) Based on the distribution of negative and positive samples, what can you say about our future predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise 4***\n",
    "Explore the number of the 'age' feature from the titanic data set.\n",
    "\n",
    "    1) How many different ages exist in our data set\n",
    "    2) How many people are 21 years old?\n",
    "    2) Are there any unexpected values in our dataset?\n",
    "    3) Remove all samples where we have an unknown age\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
